{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import datetime\n",
    "import re\n",
    "import csv\n",
    "global driver\n",
    "import bash\n",
    "driver = webdriver.Chrome('C:/Users/tosea/chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_and_end_dates(beginDate, endDate, time_interval=\"all\"):\n",
    "    dates = []\n",
    "    dt = datetime.datetime.strptime(beginDate, \"%Y%m%d\")\n",
    "    date = beginDate[:]\n",
    "    while date <= endDate:\n",
    "        if (int(dt.strftime(\"%Y\"))%4 == 0) and (dt.strftime(\"%m\") == \"01\") and (int(dt.strftime(\"%d\")) <= time_interval):\n",
    "            time_interval += 1\n",
    "            dates.append([date, (datetime.datetime.strptime(date, \"%Y%m%d\")+datetime.timedelta(time_interval-1)).strftime(\"%Y%m%d\")])\n",
    "            dt = dt + datetime.timedelta(time_interval)\n",
    "            date = dt.strftime(\"%Y%m%d\")\n",
    "            time_interval -= 1\n",
    "        else:\n",
    "            dates.append([date, (datetime.datetime.strptime(date, \"%Y%m%d\")+datetime.timedelta(time_interval-1)).strftime(\"%Y%m%d\")])\n",
    "            dt = dt + datetime.timedelta(time_interval)\n",
    "            date = dt.strftime(\"%Y%m%d\")     \n",
    "\n",
    "    if datetime.datetime.strptime(dates[-1][0], \"%Y%m%d\") < datetime.datetime.strptime(endDate, \"%Y%m%d\"):\n",
    "        date = datetime.datetime.strptime(dates[-1][0], \"%Y%m%d\")+datetime.timedelta(1)\n",
    "    dates[-1][1] = endDate\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv_title(filename, titles):\n",
    "    with open(filename, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerow(titles)\n",
    "\n",
    "def write_csv_elements(filename, elements):\n",
    "    with open(filename, 'a+', newline='', encoding=\"utf-8\") as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerow(elements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_button(button_xpath, url, sleeptime_start, sleeptime_end):\n",
    "    driver.get(url)\n",
    "    while True:\n",
    "        try:\n",
    "            element = driver.find_element_by_xpath(button_xpath)\n",
    "            element.click()\n",
    "            time.sleep(random.randint(sleeptime_start, sleeptime_end))\n",
    "        except NoSuchElementException:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_element(url, filename, rounds):\n",
    "    #press Show More button until the last line\n",
    "    list2 = []\n",
    "    driver.get(url)\n",
    "    # click \"show more\" button till the end of the page\n",
    "    while True:\n",
    "        try:\n",
    "            element = driver.find_element_by_xpath('//button[text()=\"Show More\"]')\n",
    "            element.click()\n",
    "            time.sleep(random.randint(6, 10))\n",
    "        except NoSuchElementException:\n",
    "            break\n",
    "\n",
    "    time.sleep(random.randint(4, 6))\n",
    "    \n",
    "    '''\n",
    "    # Codes below should work for counting times of writing into csv, but not working. This code need further testing\n",
    "    \n",
    "    element = driver.find_element_by_xpath('//*[contains(text(),\"PRINT EDITION\")]')\n",
    "    length = len(element.text) + 100\n",
    "    '''\n",
    "    \n",
    "    length = rounds\n",
    "\n",
    "    for i in range(1, length):  #count numbers of articles\n",
    "            \n",
    "            while True:\n",
    "                try:\n",
    "                    pubdate = driver.find_element_by_xpath(f'//*[@id=\"site-content\"]/div/div[2]/div[2]/ol/li[{i}]/div/time')\n",
    "                    list2.append(pubdate.text)\n",
    "                    break\n",
    "                except NoSuchElementException:\n",
    "                    list2.append(np.NaN)\n",
    "                    break\n",
    "            write_csv_elements(filename, list2)\n",
    "            \n",
    "            while True:\n",
    "                try:\n",
    "                    title = driver.find_element_by_xpath(f'//*[@id=\"site-content\"]/div/div[2]/div[2]/ol/li[{i}]/div/div/div/a/h4')\n",
    "                    list2.append(title.text)\n",
    "                    break\n",
    "                except NoSuchElementException:\n",
    "                    list2.append(np.NaN)\n",
    "                    break\n",
    "            \n",
    "            while True:\n",
    "                try:\n",
    "                    abstract = driver.find_element_by_xpath(f'//*[@id=\"site-content\"]/div/div[2]/div[2]/ol/li[{i}]/div/div/div/a/p')                  \n",
    "                    list2.append(abstract.text)\n",
    "                    break\n",
    "                except NoSuchElementException:\n",
    "                    list2.append(np.NaN)\n",
    "                    break\n",
    "            \n",
    "            while True:\n",
    "                try:\n",
    "                    link = driver.find_element_by_xpath(f'//*[@id=\"site-content\"]/div/div[2]/div[2]/ol/li[{i}]/div/div/div')\n",
    "                    el = link.find_element_by_css_selector(\"a\")\n",
    "                    abc = el.get_attribute(\"href\")\n",
    "                    list2.append(abc)\n",
    "                    break\n",
    "                except NoSuchElementException:\n",
    "                    list2.append(np.NaN)\n",
    "                    break\n",
    "                    \n",
    "            while True:\n",
    "                try:\n",
    "                    author = driver.find_element_by_xpath(f'//*[@id=\"site-content\"]/div/div[2]/div[2]/ol/li[{i}]/div/div/div/a/p[2]')\n",
    "                    list2.append(author.text)\n",
    "                    break\n",
    "                except NoSuchElementException:\n",
    "                    try:\n",
    "                        author = driver.find_element_by_xpath(f'//*[@id=\"site-content\"]/div/div[2]/div[2]/ol/li[{i}]/div/div/div/a/p')\n",
    "                        list2.append(author.text)\n",
    "                        break\n",
    "                    except NoSuchElementException:\n",
    "                        list2.append(np.NaN)\n",
    "                        break\n",
    "                    \n",
    "            while True:\n",
    "                try:\n",
    "                    news_desk = driver.find_element_by_xpath(f'//*[@id=\"site-content\"]/div/div[2]/div[2]/ol/li[{i}]/div/div/div/p')\n",
    "                    list2.append(news_desk.text)\n",
    "                    break\n",
    "                except NoSuchElementException:\n",
    "                    list2.append(np.NaN)\n",
    "                    break\n",
    "            '''        \n",
    "            while True:\n",
    "                try:\n",
    "                    linka = driver.find_element_by_xpath(f'//*[@id=\"site-content\"]/div/div[2]/div[2]/ol/li[{i}]/div/div/div/a')\n",
    "                    driver.find_element_by_link_text(linka.text).click()\n",
    "                    story = driver.find_element_by_xpath('//*[contains(@id, story)]')\n",
    "                    list2.append(story.text)\n",
    "                    break\n",
    "                except NoSuchElementException:\n",
    "                    list2.append(np.NaN)\n",
    "                    break\n",
    "            driver.execute_script(\"window.history.go(-1)\")\n",
    "            '''\n",
    "            \n",
    "            write_csv_elements(filename, list2)\n",
    "            list2 = []\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_cut_scrape(q, beginDate, endDate, time_interval, rounds):\n",
    "    titles = [ \"pubdate\", \"title\", \"abstract\", \"link\", \"author\", \"news_desk\"]   \n",
    "    \n",
    "    for i in get_start_and_end_dates(beginDate, endDate, time_interval):\n",
    "        filename = \"nyt\"+\"_\"+q+\"_\"+str(i[0])+\"_\"+str(i[1])+\"_\"+f\"Interval{time_interval}\"+\".csv\"\n",
    "        write_csv_title(filename, titles) \n",
    "        url= f\"https://www.nytimes.com/search?dropmab=false&endDate={i[1]}&query={q}&sort=oldest&startDate={i[0]}&types=article\"\n",
    "        scrape_element(url, filename, rounds)\n",
    "        time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_all_scrape(q, beginDate, endDate, rounds):\n",
    "\n",
    "    titles = [ \"pubdate\", \"title\", \"abstract\", \"link\", \"author\", \"news_desk\"]   \n",
    "    filename = \"nyt\"+\"_\"+q+\"_\"+str(beginDate)+\"_\"+str(endDate)+\"_\"+\"alldates\"+\".csv\"\n",
    "    write_csv_title(filename, titles) \n",
    "    url= f\"https://www.nytimes.com/search?dropmab=false&endDate={endDate}&query={q}&sort=oldest&startDate={beginDate}&types=article\"\n",
    "    scrape_element(url, filename, rounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfinal_all_scrape(\"terrorism\", \"18500101\", \"18991231\", 1000)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1850-1899 all period\n",
    "'''\n",
    "final_all_scrape(\"terrorism\", \"18500101\", \"18991231\", 1000)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfinal_all_scrape(\"terrorism\", \"19000101\", \"19091231\", 1000)\\nfinal_all_scrape(\"terrorism\", \"19100101\", \"19191231\", 1000)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1900-1919 every 10 years\n",
    "'''\n",
    "final_all_scrape(\"terrorism\", \"19000101\", \"19091231\", 1000)\n",
    "final_all_scrape(\"terrorism\", \"19100101\", \"19191231\", 1000)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(1920, 1949):\\n    final_all_scrape(\"terrorism\", f\"{i}0101\", f\"{i}1231\", 1000)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1920-1948 every year\n",
    "'''\n",
    "for i in range(1920, 1949):\n",
    "    final_all_scrape(\"terrorism\", f\"{i}0101\", f\"{i}1231\", 1000)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(1949, 1966):\\n    final_all_scrape(\"terrorism\", f\"{i}0101\", f\"{i}0430\", 1000)\\n    final_all_scrape(\"terrorism\", f\"{i}0501\", f\"{i}0731\", 1000)\\n    final_all_scrape(\"terrorism\", f\"{i}0801\", f\"{i}1231\", 1000)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1949-1965 every four months\n",
    "'''\n",
    "for i in range(1949, 1966):\n",
    "    final_all_scrape(\"terrorism\", f\"{i}0101\", f\"{i}0430\", 1000)\n",
    "    final_all_scrape(\"terrorism\", f\"{i}0501\", f\"{i}0731\", 1000)\n",
    "    final_all_scrape(\"terrorism\", f\"{i}0801\", f\"{i}1231\", 1000)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(1966, 1969):\\n    final_all_scrape(\"terrorism\", f\"{i}0101\", f\"{i}0331\", 1000)\\n    final_all_scrape(\"terrorism\", f\"{i}0401\", f\"{i}0631\", 1000)\\n    final_all_scrape(\"terrorism\", f\"{i}0701\", f\"{i}0930\", 1000)\\n    final_all_scrape(\"terrorism\", f\"{i}1001\", f\"{i}1231\", 1000)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1966-1969 every three months\n",
    "'''\n",
    "for i in range(1966, 1969):\n",
    "    final_all_scrape(\"terrorism\", f\"{i}0101\", f\"{i}0331\", 1000)\n",
    "    final_all_scrape(\"terrorism\", f\"{i}0401\", f\"{i}0631\", 1000)\n",
    "    final_all_scrape(\"terrorism\", f\"{i}0701\", f\"{i}0930\", 1000)\n",
    "    final_all_scrape(\"terrorism\", f\"{i}1001\", f\"{i}1231\", 1000)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1969-2000 every month\n",
    "\n",
    "for i in range(1995, 2001):\n",
    "    final_all_scrape(\"terrorism\", f\"{i}0101\", f\"{i}0131\", 1000)\n",
    "    final_all_scrape(\"terrorism\", f\"{i}0201\", f\"{i}0301\", 1000)\n",
    "    final_all_scrape(\"terrorism\", f\"{i}0302\", f\"{i}0331\", 1000)\n",
    "    final_all_scrape(\"terrorism\", f\"{i}0401\", f\"{i}0430\", 1000)\n",
    "    final_all_scrape(\"terrorism\", f\"{i}0501\", f\"{i}0531\", 1000)\n",
    "    final_all_scrape(\"terrorism\", f\"{i}0601\", f\"{i}0630\", 1000)\n",
    "    final_all_scrape(\"terrorism\", f\"{i}0701\", f\"{i}0731\", 1000)\n",
    "    final_all_scrape(\"terrorism\", f\"{i}0801\", f\"{i}0831\", 1000)\n",
    "    final_all_scrape(\"terrorism\", f\"{i}0901\", f\"{i}0930\", 1000)\n",
    "    final_all_scrape(\"terrorism\", f\"{i}1001\", f\"{i}1031\", 1000)\n",
    "    final_all_scrape(\"terrorism\", f\"{i}1101\", f\"{i}1130\", 1000)\n",
    "    final_all_scrape(\"terrorism\", f\"{i}1201\", f\"{i}1231\", 1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2001 Jan-Aug\n",
    "\n",
    "for i in range(2001, 2002):\n",
    "    final_all_scrape(\"terrorism\", f\"{i}0101\", f\"{i}0131\", 1000)\n",
    "    final_all_scrape(\"terrorism\", f\"{i}0201\", f\"{i}0301\", 1000)\n",
    "    final_all_scrape(\"terrorism\", f\"{i}0302\", f\"{i}0331\", 1000)\n",
    "    final_all_scrape(\"terrorism\", f\"{i}0401\", f\"{i}0430\", 1000)\n",
    "    final_all_scrape(\"terrorism\", f\"{i}0501\", f\"{i}0531\", 1000)\n",
    "    final_all_scrape(\"terrorism\", f\"{i}0601\", f\"{i}0630\", 1000)\n",
    "    final_all_scrape(\"terrorism\", f\"{i}0701\", f\"{i}0731\", 1000)\n",
    "    final_all_scrape(\"terrorism\", f\"{i}0801\", f\"{i}0831\", 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2001 Sep 01-10(10 days)\n",
    "final_all_scrape(\"terrorism\", \"20010901\", \"20010910\", 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#2001 Sep 11-30 (Daily)\n",
    "\n",
    "for i in range(11, 31):\n",
    "    final_all_scrape(\"terrorism\", f\"200109{i}\", f\"200109{i}\", 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2001 Oct-Dec (Every three days)\n",
    "final_cut_scrape(\"terrorism\", f\"20011001\", f\"20011231\", 3, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2002-2019 (Every seven days)\n",
    "final_cut_scrape(\"terrorism\", f\"20020101\", f\"20191231\", 7, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2002-2019 (Every seven days)\n",
    "#final_cut_scrape(\"terrorism\", f\"20101216\", f\"20191231\", 7, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#get links in texts\n",
    "list1 = []\n",
    "driver = webdriver.Chrome('C:/Users/tosea/chromedriver.exe')\n",
    "driver.get(url)\n",
    "\n",
    "element = driver.find_element_by_xpath('//*[contains(text(),\"PRINT EDITION\")]')\n",
    "length = len(element.text) + 1\n",
    "\n",
    "for i in range(1, length):\n",
    "    while True:\n",
    "        try:\n",
    "            ab = driver.find_element_by_xpath(f'/html/body/div[1]/div[2]/main/div/div[2]/div[2]/ol/li[{i}]/div/div/div/a/p/text()')  \n",
    "            list1.append(ab.text)\n",
    "            break\n",
    "        except NoSuchElementException:\n",
    "            list1.append(np.NaN)\n",
    "            break\n",
    "#First_link = driver.find_element_by_xpath('//*[@id=\"site-content\"]/div/div[2]/div[2]/ol/li/div/div/div')\n",
    "#el = First_link.find_element_by_css_selector(\"a\")\n",
    "#abc = el.get_attribute(\"href\")\n",
    "print(\"ok\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# get the current page url\n",
    "el = driver.find_element_by_css_selector(\"a\")\n",
    "if el:\n",
    "    url = el.get_attribute(\"href\")\n",
    "url\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "element = driver.find_element_by_xpath('//*[@id=\"site-content\"]/div/div[2]/div[2]/ol/li[2]/div/div/div/a')\n",
    "print(element.text)\n",
    "'''\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
